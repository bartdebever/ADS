{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ADS-A Week 4 Assignment*\n",
    "\n",
    "# Face Recognition with Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this partly finished notebook, the Support Vector Machine algorithm is used to recognize faces. We will use the Olivetti faces dataset, as included in Scikit-Learn library. More info at: http://scikit-learn.org/stable/datasets/olivetti_faces.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing numpy, scikit-learn, and matplotlib, the Python libraries we will be using for this analysis. \n",
    "\n",
    "First, show the versions we of these libraries (that is always wise to do in case you have to report problems running the notebooks!) and use the inline plotting mode statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Your code ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load Olivetti Face Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the olivetti faces dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading Olivetti faces from http://cs.nyu.edu/~roweis/data/olivettifaces.mat to C:\\Users\\Gebruiker\\scikit_learn_data\n",
      "Modified Olivetti faces dataset.\n",
      "\n",
      "The original database was available from\n",
      "\n",
      "    http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html\n",
      "\n",
      "The version retrieved here comes in MATLAB format from the personal\n",
      "web page of Sam Roweis:\n",
      "\n",
      "    http://www.cs.nyu.edu/~roweis/\n",
      "\n",
      "There are ten different images of each of 40 distinct subjects. For some\n",
      "subjects, the images were taken at different times, varying the lighting,\n",
      "facial expressions (open / closed eyes, smiling / not smiling) and facial\n",
      "details (glasses / no glasses). All the images were taken against a dark\n",
      "homogeneous background with the subjects in an upright, frontal position (with\n",
      "tolerance for some side movement).\n",
      "\n",
      "The original dataset consisted of 92 x 112, while the Roweis version\n",
      "consists of 64x64 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "\n",
    "# Fetch the faces data\n",
    "faces = fetch_olivetti_faces()\n",
    "print(faces.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Investigate the Olivetti Face Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the data. As you can see by running the following statement `faces` is a dictionary with the following keys: `faces.target`, `faces.images`, `DESCR`, `data`. Investigate these items. How many images are present in the dataset? What is the image size in terms of pixels? How many persons are there? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'images', 'target', 'DESCR'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(faces.keys())\n",
    "\n",
    "## Your code ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have to scale features, why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that the data is already normalized\n",
    "\n",
    "## Your code ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the first 20 images in a row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_faces(images, target, top_n):\n",
    "    # set up the figure size in inches\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    for i in range(top_n):\n",
    "        # plot the images in a matrix of 20x20\n",
    "        p = fig.add_subplot(20, 20, i + 1, xticks=[], yticks=[])\n",
    "        p.imshow(images[i], cmap=plt.cm.bone)\n",
    "        \n",
    "        # label the image with the target value\n",
    "        p.text(0, 14, str(target[i]))\n",
    "        p.text(0, 60, str(i))\n",
    "        \n",
    "print_faces(faces.images, faces.target, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all the faces in a matrix of 20x20, for each one, put the target value in the top left corner and its index in the bottom left corner.\n",
    "It may take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see now we have confirmed that there are 40 individuals with 10 different images each in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Analysis with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a classifier whose model is a hyperplane that separates instances of one class from the rest. Support Vector Machines (SVM) are supervised learning methods that try to obtain these hyperplanes in an optimal way, by selecting the ones that pass through the widest possible gaps between instances of different classes. New instances will be classified as belonging to a certain category based on which side of the surfaces they fall on. Let's import the SVC class from the sklearn.svm module. SVC stands for Support Vector Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_1 = SVC(kernel='linear')\n",
    "print(svc_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the train_test_split() function to create a train set (75%) and test set (25%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Your code ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the classifier (algorithm) defined and the train and test data available you are ready to do the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the analysis with the classifier, next predict the labels of the test set and use the accuracy_score helper \n",
    "# function to determine the accuracy.\n",
    "from sklearn import metrics\n",
    "\n",
    "## Your code ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Explanation Cross-validation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called overfitting. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a **test set**.\n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "As you have seen in scikit-learn a random split into training and test sets can be quickly computed with the ``train_test_split`` helper function. \n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "When evaluating different settings (“hyperparameters”) for estimators (such as the C setting that must be manually set for an SVM) there is still a risk of overfitting on the test set because the parameters can be tweaked until the estimator performs optimally. This way, knowledge about the test set can “leak” into the model and evaluation metrics no longer report on generalization performance. To solve this problem, yet another part of the dataset can be held out as a so-called “validation set”: training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.\n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "However the downside is that by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets.\n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "A solution to this problem is a procedure called cross-validation (CV for short). A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called k-fold CV, the training set is split into k smaller sets. The following procedure is followed for each of the k “folds”:\n",
    "•\tA model is trained using k-1 of the folds as training data;\n",
    "•\tThe resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
    "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. This approach can be computationally expensive, but does not waste too much data.\n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "The function ``KFold`` divides the dataset in k groups of samples, called folds (if k = n, this is equivalent to the Leave One Out\n",
    "strategy), of equal sizes (if possible). The prediction function is learned using k-1 folds, and the fold left out is\n",
    "used for test.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform 5-fold cross-validation. Show what all the accuracy scores are and compute the average value. Consult the sklearn documentation and when needed ask your fellow students or teacher for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "## Your code ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down your conclusion of the K-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your answer ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Optionally: More on Cross-validation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "The function ``StratifiedKFold`` is a variation of k-fold which returns stratified folds: Each set contains approximately the same percentage of samples of each target class as the complete set.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "labels = [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "skf = StratifiedKFold(labels, 3)\n",
    "for train, test in skf:\n",
    "     print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "The function ``LeaveOneOut`` (or LOO) is a simple cross-validation. Each learning set is created by taking all the samples except one, the test set being the sample left out. Thus, for n samples, we have n different training sets and n different tests set. This cross-validation procedure does not waste much data as only one sample is removed from the training set.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut(4)\n",
    "for train, test in loo:\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Potential users of LOO for model selection should weigh a few known caveats. When compared with k-fold cross validation, one builds n models from n samples instead of k models. Moreover, LOO is trained on n-1 samples rather than (k-1)/k * n. Hence LOO is computationally more expensive than k-fold cross validation.\n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "In terms of accuracy, LOO often results in high variance as an estimator for the test error. Intuitively, since n-1 of the n samples are used to build each model, models constructed from folds are virtually identical to each other and to the model built from the entire training set.\n",
    "However, if the learning curve is steep for the training size in question, then 5- or 10- fold cross validation can overestimate the generalization error.\n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "As a general rule, most authors, and empirical evidence, suggest that 5- or 10- fold cross validation should be preferred to LOO.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Optionally: Other Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the sklearn ``metrics`` package and determine also precision and recall for the test set, for _each class_. The code is given ... can you figure out what happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def train_and_evaluate(clf, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Accuracy on training set:\")\n",
    "    print(clf.score(X_train, y_train))\n",
    "    print(\"Accuracy on testing set:\")\n",
    "    print(clf.score(X_test, y_test))\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate(svc_1, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is your overall conclusion? Can you explain the confusion matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your answer\n",
    "\n",
    "#Conclusion: Performance of SVM for face recognition is incredibly high!\n",
    "#Confusion matrix: Excellent tool to find problemetic data (which face goes wrong)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Discriminate People with or without Glasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, another problem. \n",
    "\n",
    "Try to classify images of people with and without glasses. A few tips to take into account.\n",
    "- Relabel all the images (by hand, carefully look at 20x20 matrix plot above)\n",
    "- Create a training & test set for this new problem\n",
    "- Again try a [linear SVC classifier](http://en.wikipedia.org/wiki/Kernel_%28linear_algebra%29) (start by using the default parameters)\n",
    "- Do the analysis and evaluate.\n",
    "- And  show a classification report as above.\n",
    "- Which images go wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your answers ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
