{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3\n",
    "\n",
    "### The task\n",
    "For challenge 3 we are tasked to compare machine learning algorithms and see which ever one is best. Within this notebook we are going to be trying out; SVM, MLP, Random Forest, Ensemble Learning and Neural networks.\n",
    "\n",
    "### Optimizing the algorithms\n",
    "For each algorithm we will be trying to find the best possible options to get the best result out of each algorithm.\n",
    "\n",
    "### Personal goals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset\n",
    "The dataset I picked for this assignment was ***DATASET HERE*** It mostly peaked my personal interest and seemed easy enough to work with. I found this dataset on *Keggle* and [***the this is the link to the dataset***](http://google.com).\n",
    "The domain of this dataset is ***DOMAIN*** because..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepairing the notebook\n",
    "To start off this notebook we are going to be making methods. We make these to prepare for a dataset which might change. As this is the first dataset I need to pick myself, it might be a unusable dataset with features that are not good enough to use in this context. With the methods made I can simply change out the dataset and everything should still work.\n",
    "\n",
    "Since Katherine and I also did this for challenge 1 to be able to swap out the Iris and Whine set easily, I will be getting my code from the challenge 1. This will be noted in the documentation but will still be explained.\n",
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.12.1\n",
      "Pandas version: 0.20.1\n",
      "Scikit-learn version: 0.18.1\n",
      "Matplotlib version: 2.0.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "print('NumPy version:', np.__version__)\n",
    "print('Pandas version:', pd.__version__)\n",
    "print('Scikit-learn version:', sk.__version__)\n",
    "print('Matplotlib version:', matplotlib.__version__)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the dataset\n",
    "### Boxplots\n",
    "To analyze our features we want to look at the features and see how they compare. What features are good to use and where do we see the least amount of overlap. To make this easier on ourselves, we are going to write an automated method to do this work. We can just make a list of features and run these through the method and out come all the boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boxPlots(df, features, label):\n",
    "    if(len(features)>4):\n",
    "        for i in range(int(len(features)/4)+1):\n",
    "            try:\n",
    "                df.boxplot(column=features[4*i:4*(i+1)], by=label, figsize=(15,8), layout=(1,4))\n",
    "            except:\n",
    "                try:\n",
    "                    df.boxplot(column=features[4*i], by=label, figsize=(15,8), layout=(1,4))\n",
    "                    df.boxplot(column=features[4*i+1], by=label, figsize=(15,8), layout=(1,4))\n",
    "                    df.boxplot(column=features[4*i+2], by=label, figsize=(15,8), layout=(1,4))\n",
    "                    df.boxplot(column=features[4*i+3], by=label, figsize=(15,8), layout=(1,4))\n",
    "                except:\n",
    "                    df = df #Index is out of range but needs code to not go further\n",
    "    else:\n",
    "        df.boxplot(column=features, by=label, figsize=(15,8), layout=(1,4))\n",
    "#         maximums = []\n",
    "#         for i in range(len(features)):\n",
    "#             maximums.append(max(df[features[i]]))\n",
    "#         for i in range(int(len(features)/4)+1):\n",
    "#             seperate=False\n",
    "#             seperateindex = 0\n",
    "#             beginindex = 4*i\n",
    "#             endindex= 4*(i+1)\n",
    "#             equalizer = 5\n",
    "#             plotted = features[beginindex:endindex]\n",
    "#             try:\n",
    "#                 for q in range(4):\n",
    "#                     if(int(maximums[beginindex+q]/maximums[beginindex]) > equalizer) or (int(maximums[beginindex+q]/maximums[beginindex+1]) > equalizer) or(int(maximums[beginindex+q]/maximums[beginindex+2]) > equalizer) or (int(maximums[beginindex+q]/maximums[beginindex+3]) > equalizer):\n",
    "#                         seperate = True\n",
    "#                         seperateindex = q\n",
    "#             except:\n",
    "#                 seperate = True \n",
    "#             if(seperate == False):\n",
    "#                 df.boxplot(column=plotted, by=label, figsize=(15,8), layout=(1,4))\n",
    "#             else:\n",
    "#                 rest = plotted[beginindex:seperateindex] + plotted[seperateindex+1:endindex]\n",
    "#                 print(\"Index: \" + str(seperateindex))\n",
    "#                 print(len(plotted[beginindex:seperateindex]))\n",
    "#                 print(len(plotted[seperateindex+1:endindex]))\n",
    "#                 print(len(rest))\n",
    "#                 df.boxplot(column=plotted[seperateindex], by=label, figsize=(15,8), layout=(1,4))\n",
    "#                 df.boxplot(column=rest, by=label, figsize=(15,8), layout=(1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaination\n",
    "### Defining the method\n",
    "To start off, we give the method the name `boxPlots` it is descriptive enough for me and easy to type.\n",
    "#### The parameters\n",
    "    - df:       The dataframe used to visualize the features\n",
    "    - features: A Tuple of the features wanting to be analysed\n",
    "    - label:    The string of which column is the label\n",
    "```py\n",
    "def boxPlots(df, features, label):\n",
    "```\n",
    "### Checking the amount of features present\n",
    "If we have more than 4 features we want to split them up in to multiple sets of 4. This is why we do an initial check to see if we have more than 4 features.\n",
    "```py\n",
    "if(len(features)>4):\n",
    "```\n",
    "### Printing the boxplots by 4\n",
    "If there are more features than 4 we want to split these into groups of 4 and print them seperately.\n",
    "First, we make a loop by deviding the amount of features by 4 and adding 1. The `int()` method **ALWAYS** rounds downwards and this is not good for us as the last features will be cut off. This is the reason we add 1.\n",
    "Second, we want to try plotting all 4 figures at once, if this fails it is most likely an index out of range exception. To make sure all boxplots get plotted we then again implement a try in the catch to plot every single boxplot after one another.\n",
    "This isn't the most clean way to do it but it works.\n",
    "```py\n",
    "        for i in range(int(len(features)/4)+1):\n",
    "            try:\n",
    "                df.boxplot(column=features[4*i:4*(i+1)], by=label, figsize=(15,8), layout=(1,4))\n",
    "            except:\n",
    "                try:\n",
    "                    df.boxplot(column=features[4*i], by=label, figsize=(15,8), layout=(1,4))\n",
    "                    df.boxplot(column=features[4*i+1], by=label, figsize=(15,8), layout=(1,4))\n",
    "                    df.boxplot(column=features[4*i+2], by=label, figsize=(15,8), layout=(1,4))\n",
    "                    df.boxplot(column=features[4*i+3], by=label, figsize=(15,8), layout=(1,4))\n",
    "                except:\n",
    "                    df = df #Index is out of range but needs code to not go further\n",
    "                    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plots\n",
    "We can also use scatter plots to see how the features are seperated from each other. This is a very clear and visual representation of these points. Again we would like to automate things to make it easy to work with our dataset and swap features if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "def scatterplots(features, colors, labelnames, splitsize, random):    \n",
    "    for value in features:\n",
    "        names = list(value)\n",
    "        value = StandardScaler().fit(value).transform(value)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(value,y,test_size=splitsize, random_state=random)\n",
    "        for i in range(len(colors)):\n",
    "            x1s = X_train[:, 0][y_train.as_matrix() == i+1]\n",
    "            x2s = X_train[:, 1][y_train.as_matrix() == i+1]\n",
    "            plt.scatter(x1s, x2s, c=colors[i])\n",
    "\n",
    "        plt.legend(labelnames)\n",
    "        plt.xlabel(\"Normalized \" + names[0])\n",
    "        plt.ylabel(\"Normalized \" + names[1]);\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "def findKBestFeatures(df, features, label):\n",
    "    selector = SelectKBest(f_classif, k=5)\n",
    "    selector.fit(df[features], df[label])\n",
    "    scores = -np.log10(selector.pvalues_)\n",
    "    plt.bar(range(len(predictors)), scores)\n",
    "    plt.xticks(range(lenpredictors), predictors, rotation=\"vertical\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "def predictSVM(X_train, X_test, y_train, y_test, c):\n",
    "    svc = SVC(kernal='linear', C=c)\n",
    "    svc.fit(X_train, y_train)\n",
    "    return svc.predict(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "def predictTree(X_train, X_test, y_train, y_test, trees):\n",
    "    clf = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = trees, min_samples_leaf = 5)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    return clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "def predictNeuralNetwork(X_train, X_test, y_train, size, random):\n",
    "    clf = MLPClassifier(hidden_layer_sizes=size)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
